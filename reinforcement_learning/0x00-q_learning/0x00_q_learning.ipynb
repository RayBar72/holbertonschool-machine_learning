{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXFNK_qqMPx1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 0"
      ],
      "metadata": {
        "id": "7lb1r8hcgVgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "0-load_env\n",
        "\"\"\"\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_frozen_lake(desc=None, map_name=None, is_slippery=False):\n",
        "    \"\"\"\n",
        "    Function that loads the pre-made FrozenLakeEnv\n",
        "    evnironment from OpenAIâ€™s gym\n",
        "    \"\"\"\n",
        "    env = gym.make('FrozenLake-v1',\n",
        "                   desc=desc,\n",
        "                   map_name=map_name,\n",
        "                   is_slippery=is_slippery)\n",
        "    return env\n"
      ],
      "metadata": {
        "id": "cSsSsjkdMoiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "# load_frozen_lake = __import__('0-load_env').load_frozen_lake\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "env = load_frozen_lake()\n",
        "print(env.desc)\n",
        "print(env.P[0][0])\n",
        "env = load_frozen_lake(is_slippery=True)\n",
        "print(env.desc)\n",
        "print(env.P[0][0])\n",
        "desc = [['S', 'F', 'F'], ['F', 'H', 'H'], ['F', 'F', 'G']]\n",
        "env = load_frozen_lake(desc=desc)\n",
        "print(env.desc)\n",
        "env = load_frozen_lake(map_name='4x4')\n",
        "print(env.desc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c-TNmAnSG5C",
        "outputId": "12fc23d2-9b40-4217-9b4d-75947a26d75a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[b'S' b'F' b'F' b'F' b'F' b'F' b'F' b'H']\n",
            " [b'H' b'F' b'F' b'F' b'F' b'H' b'F' b'F']\n",
            " [b'F' b'H' b'F' b'H' b'H' b'F' b'F' b'F']\n",
            " [b'F' b'F' b'F' b'H' b'F' b'F' b'F' b'F']\n",
            " [b'F' b'F' b'F' b'F' b'F' b'F' b'H' b'F']\n",
            " [b'F' b'F' b'F' b'F' b'F' b'F' b'F' b'F']\n",
            " [b'F' b'F' b'F' b'F' b'H' b'F' b'F' b'F']\n",
            " [b'F' b'F' b'F' b'F' b'F' b'F' b'F' b'G']]\n",
            "[(1.0, 0, 0.0, False)]\n",
            "[[b'S' b'F' b'H' b'F' b'H' b'F' b'H' b'F']\n",
            " [b'H' b'F' b'F' b'F' b'F' b'F' b'F' b'F']\n",
            " [b'F' b'F' b'F' b'F' b'F' b'F' b'F' b'F']\n",
            " [b'F' b'H' b'F' b'F' b'F' b'F' b'F' b'F']\n",
            " [b'F' b'F' b'H' b'F' b'F' b'F' b'F' b'H']\n",
            " [b'F' b'F' b'F' b'F' b'F' b'H' b'F' b'H']\n",
            " [b'F' b'F' b'H' b'F' b'H' b'F' b'H' b'F']\n",
            " [b'F' b'F' b'H' b'F' b'F' b'F' b'F' b'G']]\n",
            "[(0.3333333333333333, 0, 0.0, False), (0.3333333333333333, 0, 0.0, False), (0.3333333333333333, 8, 0.0, True)]\n",
            "[[b'S' b'F' b'F']\n",
            " [b'F' b'H' b'H']\n",
            " [b'F' b'F' b'G']]\n",
            "[[b'S' b'F' b'F' b'F']\n",
            " [b'F' b'H' b'F' b'H']\n",
            " [b'F' b'F' b'F' b'H']\n",
            " [b'H' b'F' b'F' b'G']]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1"
      ],
      "metadata": {
        "id": "GF2sjuqUgYK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "1-q_init\n",
        "\"\"\"\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def q_init(env):\n",
        "    \"\"\"\n",
        "    Function that initializes the Q-table\n",
        "    \"\"\"\n",
        "    action = env.action_space.n\n",
        "    state = env.observation_space.n\n",
        "    q_table = np.zeros((state, action))\n",
        "    return q_table\n"
      ],
      "metadata": {
        "id": "KQ94z_pWgaUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "# load_frozen_lake = __import__('0-load_env').load_frozen_lake\n",
        "# q_init = __import__('1-q_init').q_init\n",
        "\n",
        "env = load_frozen_lake()\n",
        "Q = q_init(env)\n",
        "print(Q.shape)\n",
        "env = load_frozen_lake(is_slippery=True)\n",
        "Q = q_init(env)\n",
        "print(Q.shape)\n",
        "desc = [['S', 'F', 'F'], ['F', 'H', 'H'], ['F', 'F', 'G']]\n",
        "env = load_frozen_lake(desc=desc)\n",
        "Q = q_init(env)\n",
        "print(Q.shape)\n",
        "env = load_frozen_lake(map_name='4x4')\n",
        "Q = q_init(env)\n",
        "print(Q.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBo7lajWhKMd",
        "outputId": "5c669cb6-afc9-48d4-a3e2-ea7b6c371ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 4)\n",
            "(64, 4)\n",
            "(9, 4)\n",
            "(16, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2"
      ],
      "metadata": {
        "id": "JQIw_oC0hWT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "2-epsilon_greedy\n",
        "\"\"\"\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def epsilon_greedy(Q, state, epsilon):\n",
        "    \"\"\"\n",
        "    Function that uses epsilon-greedy to determine the next action\n",
        "    \"\"\"\n",
        "    p = np.random.uniform(0, 1)\n",
        "    x = np.random.randint(Q.shape[1])\n",
        "    if p > epsilon:\n",
        "        action = np.argmax(Q[state, :])\n",
        "    else:\n",
        "        action = x\n",
        "    return action\n"
      ],
      "metadata": {
        "id": "A7l2UB4BhYwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "# load_frozen_lake = __import__('0-load_env').load_frozen_lake\n",
        "# q_init = __import__('1-q_init').q_init\n",
        "# epsilon_greedy = __import__('2-epsilon_greedy').epsilon_greedy\n",
        "import numpy as np\n",
        "\n",
        "desc = [['S', 'F', 'F'], ['F', 'H', 'H'], ['F', 'F', 'G']]\n",
        "env = load_frozen_lake(desc=desc)\n",
        "Q = q_init(env)\n",
        "Q[7] = np.array([0.5, 0.7, 1, -1])\n",
        "np.random.seed(0)\n",
        "print(epsilon_greedy(Q, 7, 0.5))\n",
        "np.random.seed(1)\n",
        "print(epsilon_greedy(Q, 7, 0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPNL3Bsux9gZ",
        "outputId": "f32ee8df-aa52-48f1-fa47-44f3830d68a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3"
      ],
      "metadata": {
        "id": "-AwaSwQ5zfMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ITi5nDtb0I_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "3-q_learning\n",
        "\"\"\"\n",
        "import gym\n",
        "import numpy as np\n",
        "# epsilon_greedy = __import__('2-epsilon_greedy').epsilon_greedy\n",
        "\n",
        "\n",
        "def train(env, Q, episodes=5000, max_steps=100, alpha=0.1, gamma=0.99,\n",
        "          epsilon=1, min_epsilon=0.1, epsilon_decay=0.05):\n",
        "    \"\"\"\n",
        "    Function that performs Q-learning\n",
        "    \"\"\"\n",
        "    initial_epsilon = epsilon\n",
        "    total_rewards = []\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        state = env.reset()\n",
        "        rewards = 0\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            action = epsilon_greedy(Q, state, epsilon)\n",
        "\n",
        "            new_state, reward, done, info = env.step(action)\n",
        "\n",
        "            if done and reward == 0:\n",
        "                reward = -1\n",
        "\n",
        "            Q[state, action] = Q[state, action] + alpha * \\\n",
        "                (reward + gamma * np.max(Q[new_state, :]) - Q[state, action])\n",
        "\n",
        "            state = new_state\n",
        "            rewards += reward\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        total_rewards.append(rewards)\n",
        "\n",
        "        epsilon = (min_epsilon + (initial_epsilon - min_epsilon) *\n",
        "                   np.exp(-epsilon_decay * episode))\n",
        "\n",
        "    return Q, total_rewards\n"
      ],
      "metadata": {
        "id": "Fb9vnu1izhkm"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "# load_frozen_lake = __import__('0-load_env').load_frozen_lake\n",
        "# q_init = __import__('1-q_init').q_init\n",
        "# train = __import__('3-q_learning').train\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "desc = [['S', 'F', 'F'], ['F', 'H', 'H'], ['F', 'F', 'G']]\n",
        "env = load_frozen_lake(desc=desc)\n",
        "Q = q_init(env)\n",
        "\n",
        "Q, total_rewards  = train(env, Q)\n",
        "print(Q)\n",
        "split_rewards = np.split(np.array(total_rewards), 10)\n",
        "for i, rewards in enumerate(split_rewards):\n",
        "    print((i+1) * 500, ':', np.mean(rewards))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px-zeaYqhvgW",
        "outputId": "ac814ea3-f078-49ba-d8e8-8cfb28e10d81"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.96059593  0.970299    0.95098488  0.96059396]\n",
            " [ 0.96059557 -0.77123208  0.0094072   0.37627228]\n",
            " [ 0.18061285 -0.1         0.          0.        ]\n",
            " [ 0.97029877  0.9801     -0.99999988  0.96059583]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.98009763  0.98009933  0.99        0.9702983 ]\n",
            " [ 0.98009922  0.98999782  1.         -0.99999952]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "500 : 0.812\n",
            "1000 : 0.88\n",
            "1500 : 0.9\n",
            "2000 : 0.9\n",
            "2500 : 0.88\n",
            "3000 : 0.844\n",
            "3500 : 0.892\n",
            "4000 : 0.896\n",
            "4500 : 0.852\n",
            "5000 : 0.928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4"
      ],
      "metadata": {
        "id": "MVSun5ECuoYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygame \n",
        "\n",
        "# import os\n",
        "# os.environ['SDL_VIDEODRIVER']='dummy'\n",
        "import pygame\n",
        "pygame.display.set_mode((640,480))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkLOwtZAwS97",
        "outputId": "6ebfc5fa-c245-46c2-b86d-8c31196022ee"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.8/dist-packages (2.1.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Surface(640x480x32 SW)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"4-play\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def play(env, Q, max_steps=100):\n",
        "    state = env.reset()\n",
        "    env.render()\n",
        "    for step in range(max_steps):\n",
        "        action = np.argmax(Q[state])\n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        env.render()\n",
        "        if done:\n",
        "            return reward\n",
        "        state = new_state\n",
        "\n",
        "    env.close()"
      ],
      "metadata": {
        "id": "KeyaZliLuqh5"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "# load_frozen_lake = __import__('0-load_env').load_frozen_lake\n",
        "# q_init = __import__('1-q_init').q_init\n",
        "# train = __import__('3-q_learning').train\n",
        "# play = __import__('4-play').play\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "desc = [['S', 'F', 'F'], ['F', 'H', 'H'], ['F', 'F', 'G']]\n",
        "env = load_frozen_lake(desc=desc)\n",
        "Q = q_init(env)\n",
        "\n",
        "Q, total_rewards  = train(env, Q)\n",
        "print(play(env, Q))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_gA85Mmv8RW",
        "outputId": "c8b70388-cbed-46cc-f2ff-c972e7a6a817"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    }
  ]
}